{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "nba = pd.read_csv('nba.csv') \n",
    "diabetes = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "y = diabetes['Outcome']\n",
    "x = diabetes.drop('Outcome', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu')) # hidden layer where input dimensions==>no of features/inputs in dataset, always fix\n",
    "model.add(Dense(8, activation='relu')) # hidden layer, we can change\n",
    "model.add(Dense(4, activation='relu')) # hidden layer\n",
    "model.add(Dense(1, activation='sigmoid')) # output layer of binary classification where activation function should be always sigmoid , always fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 253 (1012.00 Byte)\n",
      "Trainable params: 253 (1012.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "54/54 [==============================] - 1s 2ms/step - loss: 3.1510 - accuracy: 0.4115\n",
      "Epoch 2/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 1.4873 - accuracy: 0.4246\n",
      "Epoch 3/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 1.1268 - accuracy: 0.4711\n",
      "Epoch 4/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.9415 - accuracy: 0.4879\n",
      "Epoch 5/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.8255 - accuracy: 0.5400\n",
      "Epoch 6/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.7496 - accuracy: 0.5624\n",
      "Epoch 7/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.5754\n",
      "Epoch 8/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.7196 - accuracy: 0.6201\n",
      "Epoch 9/150\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.7125 - accuracy: 0.5996\n",
      "Epoch 10/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.6425\n",
      "Epoch 11/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6990 - accuracy: 0.6313\n",
      "Epoch 12/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6777 - accuracy: 0.6406\n",
      "Epoch 13/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.6480\n",
      "Epoch 14/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6572 - accuracy: 0.6555\n",
      "Epoch 15/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6644 - accuracy: 0.6313\n",
      "Epoch 16/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6686 - accuracy: 0.6536\n",
      "Epoch 17/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6536\n",
      "Epoch 18/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.6555\n",
      "Epoch 19/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6629\n",
      "Epoch 20/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6403 - accuracy: 0.6611\n",
      "Epoch 21/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.6574\n",
      "Epoch 22/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6345 - accuracy: 0.6723\n",
      "Epoch 23/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6741\n",
      "Epoch 24/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.6592\n",
      "Epoch 25/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6741\n",
      "Epoch 26/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6258 - accuracy: 0.6778\n",
      "Epoch 27/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6275 - accuracy: 0.6778\n",
      "Epoch 28/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6221 - accuracy: 0.6685\n",
      "Epoch 29/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6345 - accuracy: 0.6741\n",
      "Epoch 30/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6187 - accuracy: 0.6983\n",
      "Epoch 31/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.6834\n",
      "Epoch 32/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.6760\n",
      "Epoch 33/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.7002\n",
      "Epoch 34/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.6872\n",
      "Epoch 35/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.7002\n",
      "Epoch 36/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6051 - accuracy: 0.6797\n",
      "Epoch 37/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.6872\n",
      "Epoch 38/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.6890\n",
      "Epoch 39/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6064 - accuracy: 0.6853\n",
      "Epoch 40/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6149 - accuracy: 0.6946\n",
      "Epoch 41/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5998 - accuracy: 0.7002\n",
      "Epoch 42/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5974 - accuracy: 0.6834\n",
      "Epoch 43/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5958 - accuracy: 0.6890\n",
      "Epoch 44/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6005 - accuracy: 0.6909\n",
      "Epoch 45/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6232 - accuracy: 0.6778\n",
      "Epoch 46/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6072 - accuracy: 0.7020\n",
      "Epoch 47/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6109 - accuracy: 0.6890\n",
      "Epoch 48/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.6797\n",
      "Epoch 49/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5896 - accuracy: 0.6946\n",
      "Epoch 50/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6056 - accuracy: 0.6983\n",
      "Epoch 51/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5928 - accuracy: 0.6890\n",
      "Epoch 52/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5938 - accuracy: 0.7002\n",
      "Epoch 53/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6103 - accuracy: 0.6685\n",
      "Epoch 54/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6275 - accuracy: 0.6741\n",
      "Epoch 55/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.6778\n",
      "Epoch 56/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5884 - accuracy: 0.6816\n",
      "Epoch 57/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5855 - accuracy: 0.6853\n",
      "Epoch 58/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.6965\n",
      "Epoch 59/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5775 - accuracy: 0.7076\n",
      "Epoch 60/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5835 - accuracy: 0.6853\n",
      "Epoch 61/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5907 - accuracy: 0.6983\n",
      "Epoch 62/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5786 - accuracy: 0.7020\n",
      "Epoch 63/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.6927\n",
      "Epoch 64/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.6983\n",
      "Epoch 65/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.6909\n",
      "Epoch 66/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.6946\n",
      "Epoch 67/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.6946\n",
      "Epoch 68/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.6965\n",
      "Epoch 69/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.7002\n",
      "Epoch 70/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.6983\n",
      "Epoch 71/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5736 - accuracy: 0.7095\n",
      "Epoch 72/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.6946\n",
      "Epoch 73/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5660 - accuracy: 0.7132\n",
      "Epoch 74/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.7058\n",
      "Epoch 75/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.7058\n",
      "Epoch 76/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.7151\n",
      "Epoch 77/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5763 - accuracy: 0.6946\n",
      "Epoch 78/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7076\n",
      "Epoch 79/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5533 - accuracy: 0.7207\n",
      "Epoch 80/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5462 - accuracy: 0.7151\n",
      "Epoch 81/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5523 - accuracy: 0.7207\n",
      "Epoch 82/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5497 - accuracy: 0.7356\n",
      "Epoch 83/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5425 - accuracy: 0.7114\n",
      "Epoch 84/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.7058\n",
      "Epoch 85/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5506 - accuracy: 0.7244\n",
      "Epoch 86/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5389 - accuracy: 0.7207\n",
      "Epoch 87/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5313 - accuracy: 0.7300\n",
      "Epoch 88/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5403 - accuracy: 0.7337\n",
      "Epoch 89/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5370 - accuracy: 0.7318\n",
      "Epoch 90/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5441 - accuracy: 0.7244\n",
      "Epoch 91/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5327 - accuracy: 0.7337\n",
      "Epoch 92/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5336 - accuracy: 0.7132\n",
      "Epoch 93/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5331 - accuracy: 0.7412\n",
      "Epoch 94/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5275 - accuracy: 0.7430\n",
      "Epoch 95/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5230 - accuracy: 0.7356\n",
      "Epoch 96/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5234 - accuracy: 0.7318\n",
      "Epoch 97/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5301 - accuracy: 0.7244\n",
      "Epoch 98/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5354 - accuracy: 0.7356\n",
      "Epoch 99/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5213 - accuracy: 0.7356\n",
      "Epoch 100/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5258 - accuracy: 0.7393\n",
      "Epoch 101/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.7393\n",
      "Epoch 102/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5060 - accuracy: 0.7412\n",
      "Epoch 103/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 0.7393\n",
      "Epoch 104/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.7188\n",
      "Epoch 105/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5159 - accuracy: 0.7430\n",
      "Epoch 106/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5267 - accuracy: 0.7412\n",
      "Epoch 107/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5189 - accuracy: 0.7412\n",
      "Epoch 108/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.7579\n",
      "Epoch 109/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.7654\n",
      "Epoch 110/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7412\n",
      "Epoch 111/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.7449\n",
      "Epoch 112/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5010 - accuracy: 0.7505\n",
      "Epoch 113/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7337\n",
      "Epoch 114/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.7318\n",
      "Epoch 115/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.7393\n",
      "Epoch 116/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.7486\n",
      "Epoch 117/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.7523\n",
      "Epoch 118/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.7430\n",
      "Epoch 119/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.7505\n",
      "Epoch 120/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7486\n",
      "Epoch 121/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4976 - accuracy: 0.7598\n",
      "Epoch 122/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7542\n",
      "Epoch 123/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4976 - accuracy: 0.7505\n",
      "Epoch 124/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.7467\n",
      "Epoch 125/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.7505\n",
      "Epoch 126/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.7486\n",
      "Epoch 127/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.7430\n",
      "Epoch 128/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7579\n",
      "Epoch 129/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7486\n",
      "Epoch 130/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7635\n",
      "Epoch 131/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7635\n",
      "Epoch 132/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.7616\n",
      "Epoch 133/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7616\n",
      "Epoch 134/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5180 - accuracy: 0.7300\n",
      "Epoch 135/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.7412\n",
      "Epoch 136/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.7561\n",
      "Epoch 137/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7635\n",
      "Epoch 138/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.7691\n",
      "Epoch 139/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.7672\n",
      "Epoch 140/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.7467\n",
      "Epoch 141/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7505\n",
      "Epoch 142/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4854 - accuracy: 0.7449\n",
      "Epoch 143/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7598\n",
      "Epoch 144/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7579\n",
      "Epoch 145/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7635\n",
      "Epoch 146/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.7430\n",
      "Epoch 147/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.7542\n",
      "Epoch 148/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.7449\n",
      "Epoch 149/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7561\n",
      "Epoch 150/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4757 - accuracy: 0.7635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1cb8b8fd9d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(x_train, y_train, epochs=150, batch_size=10) \n",
    "\n",
    "# train data/batch size ===>540/10 = 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the keras model\n",
    "accuracy = model.evaluate(x, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8-Sept-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "nba = pd.read_csv('nba.csv') \n",
    "diabetes = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "y = diabetes['Outcome']\n",
    "x = diabetes.drop('Outcome', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(x,y, train_size = 0.6, random_state= 0) #40 temp \n",
    "x_test, x_val, y_test, y_val = train_test_split(x_temp,y_temp, test_size = 0.5, random_state= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(x_train.shape)\n",
    "print(x_temp.shape)\n",
    "print(x_test.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=8, activation='relu')) # input layer +  hidden layer where input dimensions==>no of features/inputs in dataset\n",
    "model.add(Dense(32, activation='relu')) # hidden layer, we can change\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu')) # hidden layer\n",
    "model.add(Dense(1, activation='sigmoid')) # output layer of binary classification where activation function should be always sigmoid , always fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 64)                576       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 20)                660       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 12)                252       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3681 (14.38 KB)\n",
      "Trainable params: 3681 (14.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.7609 - val_loss: 0.7624 - val_accuracy: 0.6948\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7522 - val_loss: 0.7070 - val_accuracy: 0.7338\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7739 - val_loss: 0.7169 - val_accuracy: 0.7208\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7891 - val_loss: 0.7228 - val_accuracy: 0.7532\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7500 - val_loss: 0.6732 - val_accuracy: 0.7143\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7457 - val_loss: 0.7491 - val_accuracy: 0.7013\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7609 - val_loss: 0.7671 - val_accuracy: 0.6948\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7543 - val_loss: 0.7275 - val_accuracy: 0.7662\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7761 - val_loss: 0.7303 - val_accuracy: 0.7597\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7717 - val_loss: 0.6958 - val_accuracy: 0.7403\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7717 - val_loss: 0.7765 - val_accuracy: 0.7143\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7413 - val_loss: 0.7679 - val_accuracy: 0.7143\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7783 - val_loss: 0.7246 - val_accuracy: 0.7597\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7848 - val_loss: 0.7202 - val_accuracy: 0.7403\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7587 - val_loss: 0.7972 - val_accuracy: 0.6818\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7826 - val_loss: 0.7216 - val_accuracy: 0.7208\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7696 - val_loss: 0.6821 - val_accuracy: 0.7078\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7696 - val_loss: 0.7184 - val_accuracy: 0.7403\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7804 - val_loss: 0.7694 - val_accuracy: 0.7597\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7935 - val_loss: 0.7668 - val_accuracy: 0.7078\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7717 - val_loss: 0.8062 - val_accuracy: 0.7078\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7761 - val_loss: 0.8227 - val_accuracy: 0.7143\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7848 - val_loss: 0.7556 - val_accuracy: 0.6948\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7652 - val_loss: 0.7587 - val_accuracy: 0.6948\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7739 - val_loss: 0.7702 - val_accuracy: 0.6948\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7783 - val_loss: 0.7512 - val_accuracy: 0.7922\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7913 - val_loss: 0.8131 - val_accuracy: 0.7662\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7870 - val_loss: 0.7330 - val_accuracy: 0.7078\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7913 - val_loss: 0.7412 - val_accuracy: 0.7078\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7739 - val_loss: 0.8133 - val_accuracy: 0.7013\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.8065 - val_loss: 0.7985 - val_accuracy: 0.6948\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7848 - val_loss: 0.8149 - val_accuracy: 0.7013\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7913 - val_loss: 0.8006 - val_accuracy: 0.7013\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7913 - val_loss: 0.7620 - val_accuracy: 0.7468\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.8043 - val_loss: 0.8364 - val_accuracy: 0.6948\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7783 - val_loss: 0.7787 - val_accuracy: 0.7078\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7848 - val_loss: 0.7773 - val_accuracy: 0.7273\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7761 - val_loss: 0.8195 - val_accuracy: 0.7013\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8022 - val_loss: 0.7583 - val_accuracy: 0.7143\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7739 - val_loss: 0.6935 - val_accuracy: 0.7143\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7674 - val_loss: 0.8192 - val_accuracy: 0.7013\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7848 - val_loss: 0.7439 - val_accuracy: 0.6883\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7717 - val_loss: 0.7880 - val_accuracy: 0.7273\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7783 - val_loss: 0.7624 - val_accuracy: 0.7338\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.8022 - val_loss: 0.7559 - val_accuracy: 0.7143\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8087 - val_loss: 0.8345 - val_accuracy: 0.7013\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8065 - val_loss: 0.7945 - val_accuracy: 0.7208\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7935 - val_loss: 0.8276 - val_accuracy: 0.7208\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7783 - val_loss: 0.7682 - val_accuracy: 0.7078\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.7457 - val_loss: 0.8206 - val_accuracy: 0.6948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1cb8fe1b110>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),epochs=50, batch_size=20) #verebose = 0\n",
    "\n",
    "# train data/batch size ===>540/10 = 54"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
